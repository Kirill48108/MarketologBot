import logging
import os
import random
import re
from typing import Any, List, Optional

from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential_jitter

logger = logging.getLogger("app.services.llm")

DEFAULT_TOPICS: List[str] = [
    "–ü–æ–ª–µ–∑–Ω—ã–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –∏ –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç",
    "–î–∏—Å–∫—É—Å—Å–∏–∏ –æ —Ä–∞–±–æ—Ç–µ, –∫–∞—Ä—å–µ—Ä–µ –∏ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–∏",
    "–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏",
    "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤",
    "–û—Ç–Ω–æ—à–µ–Ω–∏—è, –æ–±—â–µ–Ω–∏–µ –∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∫–æ–º—Ñ–æ—Ä—Ç",
    "–•–æ–±–±–∏, –æ—Ç–¥—ã—Ö, –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è –∏ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è",
    "–§–∏–Ω–∞–Ω—Å—ã, —ç–∫–æ–Ω–æ–º–∏—è –∏ –æ—Å–æ–∑–Ω–∞–Ω–Ω—ã–µ –ø–æ–∫—É–ø–∫–∏",
    "–ó–¥–æ—Ä–æ–≤—å–µ, —Å–ø–æ—Ä—Ç –∏ —Ö–æ—Ä–æ—à–µ–µ —Å–∞–º–æ—á—É–≤—Å—Ç–≤–∏–µ",
    "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –æ–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–º—É –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è",
    "–¶–µ–ª–∏, –ø–ª–∞–Ω—ã –∏ –ª–∏—á–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
]

_SANITIZE_PREFIXES = (
    "–æ—Ç–≤–µ—Ç:",
    "–æ—Ç–≤–µ—Ç",
    "reply:",
    "reply",
    "—Ç–µ–º–∞:",
    "topic:",
    "system:",
    "user:",
    "assistant:",
)

_LATIN_RE = re.compile(r"[A-Za-z]")
_CJK_RE = re.compile(r"[\u3400-\u9FFF\uF900-\uFAFF]")
_CYRILLIC_RE = re.compile(r"[–ê-–Ø–∞-—è–Å—ë]")
_EMOJI_RE = re.compile(
    r"[\u2600-\u27BF\u1F300-\u1F6FF\u1F700-\u1F77F\u1F780-\u1F7FF\u1F800-\u1F8FF\u1F900-\u1F9FF\u1FA00-\u1FAFF]",
    flags=re.UNICODE,
)
_URL_RE = re.compile(r"http[s]?://\S+|www\.\S+", flags=re.IGNORECASE)
_END_PUNCT_RE = re.compile(r"[.!?‚Ä¶]$")
_CYR_WORD_RE = re.compile(r"\b[–ê-–Ø–∞-—è–Å—ë][–ê-–Ø–∞-—è–Å—ë\-]{1,}\b")

# –≠–º–æ–¥–∑–∏ –¥–ª—è —Ç–∏—Ö–∏—Ö —Ñ–æ–ª–±—ç–∫–æ–≤
_FALLBACK_EMOJIS = ["üôÇ", "üòä", "üòâ", "üòÑ", "üëç", "üëå", "ü§ù", "ü§î", "üòÅ", "üòå"]


def _sanitize(text: str) -> str:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–∞—è —á–∏—Å—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —à—Ç—É–∫–∏ –∏ –∫–æ–¥, –Ω–æ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º —Å–∞–º —Ç–µ–∫—Å—Ç –∏ —ç–º–æ–¥–∑–∏.
    """
    if not text:
        return ""
    t = text.strip()
    # —É–±—Ä–∞—Ç—å –±–ª–æ–∫–∏ –∫–æ–¥–∞
    t = re.sub(r"```.+?```", " ", t, flags=re.S)
    # —É–±—Ä–∞—Ç—å –∫–∞–≤—ã—á–∫–∏ –ø–æ –∫—Ä–∞—è–º
    t = t.strip(" \"'‚Äú‚Äù¬´¬ª")
    # —É–±—Ä–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã (–æ—Ç–≤–µ—Ç:, reply:, user: –∏ —Ç.–¥.)
    low = t.lower()
    for p in _SANITIZE_PREFIXES:
        if low.startswith(p):
            t = re.sub(rf"(?i)^{re.escape(p)}\s*[:\-‚Äì‚Äî]?\s*", "", t).lstrip()
            break
    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã
    t = re.sub(r"\s+", " ", t).strip()
    return t


def _normalize_emojis_to_end(text: str, max_emoji: int = 2) -> str:
    """
    –õ—ë–≥–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –µ—Å–ª–∏ —ç–º–æ–¥–∑–∏ —Ä–∞–∑–º–∞–∑–∞–Ω—ã –ø–æ —Ç–µ–∫—Å—Ç—É, —Å–æ–±–µ—Ä—ë–º –¥–æ max_emoji –≤ –∫–æ–Ω–µ—Ü.
    –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ —ç–º–æ–¥–∑–∏ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
    """
    if not text:
        return text
    # –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –±—É–∫–≤/—Ü–∏—Ñ—Ä, —Ç–æ —ç—Ç–æ –∏ —Ç–∞–∫ ¬´—ç–º–æ–¥–∑–∏‚Äë—Å–æ–æ–±—â–µ–Ω–∏–µ¬ª ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    if not re.search(r"\w", text, flags=re.UNICODE):
        return text

    emojis = _EMOJI_RE.findall(text)
    if not emojis:
        return text

    kept = emojis[:max_emoji]
    no_emoji_text = _EMOJI_RE.sub("", text).strip()
    if not no_emoji_text:
        # –í—Å—ë –±—ã–ª–æ —ç–º–æ–¥–∑–∏ ‚Äî –≤–µ—Ä–Ω—ë–º –∏—Å—Ö–æ–¥–Ω–æ–µ
        return text

    if not no_emoji_text.endswith(" "):
        no_emoji_text += " "
    no_emoji_text += "".join(kept)
    return no_emoji_text.strip()


def _soft_truncate(text: str, max_len: int) -> str:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞: —Å—Ç–∞—Ä–∞–µ–º—Å—è –Ω–µ —Ä–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ.
    1) –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–æ—Ä–æ—á–µ max_len ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å;
    2) –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç–æ—á–∫—É/–≤–æ—Å–∫–ª./–≤–æ–ø—Ä–æ—Å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö max_len;
    3) –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª;
    4) –µ—Å–ª–∏ —Ç–æ–∂–µ –Ω–µ—Ç ‚Äî —Ä–µ–∂–µ–º –∂—ë—Å—Ç–∫–æ –ø–æ max_len.
    """
    if len(text) <= max_len:
        return text
    snippet = text[:max_len]
    # —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    for ch in ".!?‚Ä¶":
        idx = snippet.rfind(ch)
        if idx != -1 and idx >= max_len // 2:
            return snippet[: idx + 1].strip()
    # –ø–æ—Ç–æ–º ‚Äî –±–ª–∏–∂–∞–π—à–∏–π –ø—Ä–æ–±–µ–ª
    space_idx = snippet.rfind(" ")
    if space_idx != -1 and space_idx >= max_len // 2:
        return snippet[:space_idx].strip()
    # –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ ‚Äî –∂—ë—Å—Ç–∫–∞—è –æ–±—Ä–µ–∑–∫–∞
    return snippet.strip()


def _basic_lang_ok(text: str) -> bool:
    if not _CYRILLIC_RE.search(text):
        return False
    if _LATIN_RE.search(text):
        return False
    if _CJK_RE.search(text):
        return False
    if _URL_RE.search(text):
        return False
    return True


def _is_valid(text: str, min_len: int, max_len: int) -> bool:
    if not text:
        return False
    t = text.strip()
    if len(t) < min_len or len(t) > max_len:
        return False
    if not _basic_lang_ok(t):
        return False
    if re.fullmatch(r"[\W_]+", t, flags=re.UNICODE):
        return False
    if "```" in t:
        return False
    if len(_CYR_WORD_RE.findall(t)) < 3:
        return False
    if not re.match(r"^[–ê-–Ø–∞-—è–Å—ë]", t):
        return False
    if not _END_PUNCT_RE.search(t):
        return False
    return True


def _safe_fallback(topic: str) -> str:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ–ª–±—ç–∫: 1‚Äì3 –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —ç–º–æ–¥–∑–∏.
    –ù—É–∂–µ–Ω, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –∏–ª–∏ –≤—Å—ë —Å–æ–≤—Å–µ–º —Å–ª–æ–º–∞–ª–æ—Å—å.
    """
    count = random.randint(1, 3)
    emojis = random.sample(_FALLBACK_EMOJIS, k=count)
    return "".join(emojis)


def _is_offtopic(text: str, seed: str) -> bool:
    """
    –û—Ñ—Ñ—Ç–æ–ø –Ω–µ —Ä–µ–∂–µ–º, –ø–æ–∑–≤–æ–ª—è–µ–º –≥–æ–≤–æ—Ä–∏—Ç—å –Ω–∞ –ª—é–±—ã–µ —Ç–µ–º—ã.
    """
    return False


class LLMClient:
    def __init__(
        self,
        api_key: str,
        model: str,
        base_url: Optional[str] = None,
        style_prompt: Optional[str] = None,
        extra_topics: Optional[List[str]] = None,
        temperature: Optional[float] = None,
        min_len: Optional[int] = None,
        max_len: Optional[int] = None,
        max_emojis: Optional[int] = None,
    ):
        # OpenAI-compatible –∫–ª–∏–µ–Ω—Ç (–≤ —Ç.—á. Ollama)
        self.client: Any = AsyncOpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.style_prompt = style_prompt or ""
        self.topics = (extra_topics or []) + DEFAULT_TOPICS

        def _env_float(k: str, d: float) -> float:
            try:
                v = os.getenv(k)
                return float(v) if v is not None else d
            except Exception:
                return d

        def _env_int(k: str, d: int) -> int:
            try:
                v = os.getenv(k)
                return int(v) if v is not None else d
            except Exception:
                return d

        def _env_bool(k: str, d: bool) -> bool:
            v = os.getenv(k)
            if v is None:
                return d
            return str(v).strip().lower() in ("1", "true", "yes", "y", "on")

        # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ .env
        self.temperature = (
            temperature if temperature is not None else _env_float("LLM_TEMPERATURE", 0.30)
        )
        self.min_len = min_len if min_len is not None else _env_int("LLM_MIN_LEN", 60)
        self.max_len = max_len if max_len is not None else _env_int("LLM_MAX_LEN", 250)
        self.max_emojis = max_emojis if max_emojis is not None else _env_int("LLM_MAX_EMOJIS", 2)
        self.strict_validate = _env_bool("LLM_STRICT_VALIDATE", True)

        # —Ä—É—á–∫–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        self.top_p = _env_float("LLM_TOP_P", 0.9)
        self.frequency_penalty = _env_float("LLM_FREQUENCY_PENALTY", 0.2)
        self.presence_penalty = _env_float("LLM_PRESENCE_PENALTY", 0.1)

        logger.info(
            "LLMClient init: strict_validate=%s, min_len=%s, max_len=%s",
            self.strict_validate,
            self.min_len,
            self.max_len,
        )

    @retry(stop=stop_after_attempt(3), wait=wait_exponential_jitter(initial=0.5, max=5))
    async def generate_random_message(self, seed_hint: Optional[str] = None) -> str:
        topic = (seed_hint or "").strip() or random.choice(self.topics)
        system = (
            "–¢—ã –ø–∏—à–µ—à—å –æ–¥–Ω–æ –∫–æ—Ä–æ—Ç–∫–æ–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏ –≤ Telegram. "
            "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –±–µ–∑ —Å—Å—ã–ª–æ–∫ –∏ –ª–∞—Ç–∏–Ω–∏—Ü—ã. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π —Ç–µ–º—É, –≥–æ–≤–æ—Ä–∏ –ø–æ –¥–µ–ª—É, –±–µ–∑ —Ñ–ª—É–¥–∞. "
            f"–ü–∏—à–∏ –ø—Ä–∏–º–µ—Ä–Ω–æ {self.min_len}‚Äì{self.max_len} —Å–∏–º–≤–æ–ª–æ–≤. "
            "–¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç."
        )
        if self.style_prompt:
            system += f" –°—Ç–∏–ª—å: {self.style_prompt}"
        messages = [
            {"role": "system", "content": system},
            {
                "role": "user",
                "content": f"–û—Å—Ç–∞–≤—å –∫–æ—Ä–æ—Ç–∫–∏–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ —Ç–µ–º–µ: ¬´{topic}¬ª. –ë–µ–∑ —Å—Å—ã–ª–æ–∫.",
            },
        ]
        resp = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            top_p=self.top_p,
            max_tokens=min(4096, int(self.max_len * 1.3)),
            presence_penalty=self.presence_penalty,
            frequency_penalty=self.frequency_penalty,
        )

        # –ö–æ—Ä–æ—Ç–∫–∏–π –ª–æ–≥ ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª –æ—Ç LLM (random)
        try:
            raw_debug = (resp.choices[0].message.content or "").strip()
            logger.info("LLM raw (random) len=%s preview=%r", len(raw_debug), raw_debug[:120])
        except Exception as e:
            logger.warning("LLM raw (random) debug logging failed: %s", e)

        raw = (resp.choices[0].message.content or "").strip()

        # strict_validate = False ‚Üí –≤–æ–æ–±—â–µ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏, —Ç–æ–ª—å–∫–æ –º—è–≥–∫–æ –æ–±—Ä–µ–∑–∞–µ–º –ø–æ –¥–ª–∏–Ω–µ
        if not self.strict_validate:
            if raw:
                return _soft_truncate(raw, self.max_len)
            return _safe_fallback(topic)

        # strict_validate = True ‚Üí —Å—Ç—Ä–æ–≥–∞—è –ª–æ–≥–∏–∫–∞
        text = _sanitize(raw)
        text = _normalize_emojis_to_end(text, max_emoji=self.max_emojis)

        if _is_valid(text, self.min_len, self.max_len):
            return text
        if text and _basic_lang_ok(text):
            return text[: self.max_len]
        return _safe_fallback(topic)

    @retry(stop=stop_after_attempt(3), wait=wait_exponential_jitter(initial=0.5, max=5))
    async def generate_contextual_message(
        self, post_text: str, comment_text: Optional[str] = None
    ) -> str:
        """
        –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: –¥–æ 3 –ø–æ–ø—ã—Ç–æ–∫ + –º—è–≥–∫–∏–π/–∂—ë—Å—Ç–∫–∏–π —Ñ–æ–ª–±—ç–∫–∏.
        """
        post_excerpt = _sanitize(post_text or "")[:400]
        comment_excerpt = _sanitize(comment_text or "")[:200] if comment_text else None

        system = (
            "–¢—ã –ø–∏—à–µ—à—å –æ–¥–Ω–æ –∫–æ—Ä–æ—Ç–∫–æ–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏ –≤ Telegram. "
            "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –±–µ–∑ —Å—Å—ã–ª–æ–∫ –∏ –ª–∞—Ç–∏–Ω–∏—Ü—ã. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π —Ç–µ–º—É –ø–æ—Å—Ç–∞ –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –≥–æ–≤–æ—Ä–∏ –ø–æ –¥–µ–ª—É, –±–µ–∑ —Ñ–ª—É–¥–∞. "
            f"–ü–∏—à–∏ –ø—Ä–∏–º–µ—Ä–Ω–æ {self.min_len}‚Äì{self.max_len} —Å–∏–º–≤–æ–ª–æ–≤. "
            "–û—Ç–≤–µ—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫. –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç."
        )
        if self.style_prompt:
            system += f" –°—Ç–∏–ª—å: {self.style_prompt}"

        if comment_excerpt:
            user_base = f"–¢–µ–º–∞ –ø–æ—Å—Ç–∞: ¬´{post_excerpt}¬ª. –û—Ç–≤–µ—Ç—å –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: ¬´{comment_excerpt}¬ª."
        else:
            user_base = f"–û—Å—Ç–∞–≤—å –∫–æ—Ä–æ—Ç–∫–∏–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ —Ç–µ–º–µ –ø–æ—Å—Ç–∞: ¬´{post_excerpt}¬ª."

        attempts = [
            (self.temperature, user_base),
            (max(0.0, self.temperature - 0.04), user_base + " –ù–µ –º–µ–Ω—è–π —Ç–µ–º—É."),
            (
                min(1.0, self.temperature + 0.04),
                user_base + " –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑, –±—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ –ø–æ —Ç–µ–º–µ.",
            ),
        ]
        last_sanitized = ""
        for temperature, user in attempts:
            resp = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
                top_p=self.top_p,
                max_tokens=min(4096, int(self.max_len * 1.3)),
                presence_penalty=self.presence_penalty,
                frequency_penalty=self.frequency_penalty,
            )

            # –ö–æ—Ä–æ—Ç–∫–∏–π –ª–æ–≥ ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª –æ—Ç LLM (context)
            try:
                raw_debug = (resp.choices[0].message.content or "").strip()
                logger.info(
                    "LLM raw (context) len=%s preview=%r temp=%.2f",
                    len(raw_debug),
                    raw_debug[:120],
                    temperature,
                )
            except Exception as e:
                logger.warning("LLM raw (context) debug logging failed: %s", e)

            raw = (resp.choices[0].message.content or "").strip()

            # strict_validate=False ‚Äî –≤–æ–æ–±—â–µ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º —Ç–µ–∫—Å—Ç, —Å—Ä–∞–∑—É –º—è–≥–∫–æ –æ–±—Ä–µ–∑–∞–µ–º —Å—ã—Ä–æ–µ
            if not self.strict_validate:
                if raw:
                    return _soft_truncate(raw, self.max_len)
                # –µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ–ø—ã—Ç–∫–∏
                continue

            # strict_validate=True ‚Äî —Å—Ç—Ä–æ–≥–∞—è –ª–æ–≥–∏–∫–∞
            text = _sanitize(raw)
            text = _normalize_emojis_to_end(text, max_emoji=self.max_emojis)

            if _is_valid(text, self.min_len, self.max_len):
                return text
            if text:
                last_sanitized = text

        # strict_validate=False: –µ—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –≤–µ—Ä–Ω—É–ª–∏ –ø—É—Å—Ç–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ–ª–±—ç–∫
        if not self.strict_validate:
            seed = post_excerpt or (comment_excerpt or "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ")
            return _safe_fallback(seed)

        # strict_validate=True: –º—è–≥–∫–∏–π —Ñ–æ–ª–±—ç–∫ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –≤–∞—Ä–∏–∞–Ω—Ç—É
        if last_sanitized and _basic_lang_ok(last_sanitized):
            return last_sanitized[: self.max_len]
        seed = post_excerpt or (comment_excerpt or "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ")
        return _safe_fallback(seed)

    @staticmethod
    def extract_seed_from_post(post_text: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç ¬´—Å–µ–º—è¬ª –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å—Ç–∞: —É–±–∏—Ä–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—ã–µ –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞.
        –ù—É–∂–µ–Ω –¥–ª—è —Ñ–æ–ª–±—ç–∫–∞ random-—Å—Ü–µ–Ω–∞—Ä–∏—è, –∫–æ–≥–¥–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ.
        """
        t = (post_text or "").lower()
        t = re.sub(r"http\S+", " ", t)
        words = [w for w in re.findall(r"[a-z–∞-—è0-9\-]+", t, flags=re.IGNORECASE) if len(w) > 2]
        return " ".join(words[:8]) if words else ""
